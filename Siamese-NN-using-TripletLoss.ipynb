{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/eroj333/learning-cv-ml/blob/master/SNN/Offline%20Triplet%20Mining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "4E6B7BbMyfbj",
    "outputId": "7b7cb4eb-cde5-4803-9296-688683c9666c"
   },
   "outputs": [],
   "source": [
    "import keras as k\n",
    "import keras.backend as K\n",
    "import numpy as np \n",
    "from keras.layers import *\n",
    "from keras.models import Sequential, Model\n",
    "from keras.regularizers import l2\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.optimizers import Adam, Adadelta\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import os \n",
    "import cv2\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'E:\\hackathon\\\\trainset\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(path):\n",
    "    X_train = []\n",
    "    train_labels = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for img_path in files:\n",
    "            if img_path.endswith(\".jpg\"):\n",
    "                img_abs_path = os.path.abspath(os.path.join(root, img_path))\n",
    "                try:\n",
    "                    image = cv2.imread(img_abs_path)\n",
    "                    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "                    rez_img = cv2.resize(gray_image, (60, 60))\n",
    "                    X_train.append(rez_img)\n",
    "                    labelPath = os.path.split(img_abs_path)[0]\n",
    "                    label = os.path.split(labelPath)[1]\n",
    "                    train_labels.append(label)\n",
    "                except:\n",
    "                    print(img_abs_path,'image reading error')\n",
    "    X_train = np.array(X_train)\n",
    "    train_labels = np.array(train_labels)\n",
    "    #X_train = np.expand_dims(X_train, axis=(-1))\n",
    "    X_train = X_train.reshape(X_train.shape[0], 60, 60, 1)\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_train /= 255\n",
    "    \n",
    "    return X_train,train_labels\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train_master, y_train_master) = process_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "YH1ibN4xNpFy",
    "outputId": "e2b96d17-cc5d-4137-c98b-36e32b1151b1"
   },
   "outputs": [],
   "source": [
    "x_train_master.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hj-jCtea2Tdh"
   },
   "outputs": [],
   "source": [
    "y_train_master = y_train_master.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m3y6vlC5Q8ZE"
   },
   "outputs": [],
   "source": [
    "num_train_per_class = 5\n",
    "n_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lDG4HjBDz2sm"
   },
   "outputs": [],
   "source": [
    "def generate_triplets(dataset, label, sample_per_class=10):\n",
    "    x, y = None, None\n",
    "    for i in os.listdir(path+'\\\\train'):\n",
    "        pos_indices = np.argwhere(label == i)[:,0]\n",
    "        neg_indices = np.argwhere(label != i)[:,0]\n",
    "\n",
    "        # print(\"pos indices: {}, neg_indices: {}\".format(pos_indices.shape, neg_indices.shape))\n",
    "        choice_anchor = np.random.choice(pos_indices.shape[0], sample_per_class, replace=True)\n",
    "        choice_anchor = pos_indices[choice_anchor]\n",
    "\n",
    "        choice_pos = np.random.choice(pos_indices.shape[0], sample_per_class, replace=True)\n",
    "        choice_pos = pos_indices[choice_pos]\n",
    "\n",
    "        choice_neg = np.random.choice(neg_indices.shape[0], sample_per_class, replace=True)\n",
    "        choice_neg = neg_indices[choice_neg]\n",
    "\n",
    "        sub_x_anc = dataset[choice_anchor]\n",
    "    \n",
    "        sub_x_pos = dataset[choice_pos]\n",
    "\n",
    "        sub_x_neg = dataset[choice_neg]\n",
    "      \n",
    "        \n",
    "        if(x is None):\n",
    "            x = [(sub_x_anc), (sub_x_pos), (sub_x_neg)]\n",
    "            y = [label[choice_anchor], label[choice_pos], label[choice_neg]]\n",
    "        else:\n",
    "            x[0] = np.vstack((x[0], (sub_x_anc)))\n",
    "            x[1] = np.vstack((x[1], (sub_x_pos)))\n",
    "            x[2] = np.vstack((x[2], (sub_x_neg)))\n",
    "\n",
    "            y[0] = np.hstack((y[0].flatten(), label[choice_anchor].flatten()))\n",
    "            y[1] = np.hstack((y[1].flatten(), label[choice_pos].flatten()))\n",
    "            y[2] = np.hstack((y[2].flatten(), label[choice_neg].flatten()))\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gaC17fTD2EOz"
   },
   "outputs": [],
   "source": [
    "train_x, train_y = generate_triplets(x_train_master, y_train_master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "994sxCFpN1M_",
    "outputId": "211c5e9e-9ad5-467c-b1d9-ce6c4d17f81f"
   },
   "outputs": [],
   "source": [
    "train_x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gTQSvPXV2e48"
   },
   "outputs": [],
   "source": [
    "def visualize_data(data, n):\n",
    "  n = min(len(data[0]), n)\n",
    "  random_choices = np.random.choice(len(data[0]),n, replace=False)\n",
    "  fig, ax = plt.subplots(n, 3,figsize=(10,40))\n",
    "  anc, pos, neg = data\n",
    "  for i,ch in enumerate(random_choices):\n",
    "    ax[i, 0].imshow(np.squeeze(anc[ch] ))\n",
    "    ax[i, 1].imshow(np.squeeze(pos[ch] ))\n",
    "    ax[i, 2].imshow(np.squeeze(neg[ch] ))\n",
    "    \n",
    "\n",
    "    ax[i, 0].set_axis_off()\n",
    "    ax[i, 1].set_axis_off()\n",
    "    ax[i, 2].set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "NsEkl0Zx3pyN",
    "outputId": "7f058fcf-944e-4012-b7a2-a3258cea22e6"
   },
   "outputs": [],
   "source": [
    "visualize_data(train_x, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sj89cO8g5997"
   },
   "outputs": [],
   "source": [
    "train_x, train_y = generate_triplets(x_train_master, y_train_master, num_train_per_class)\n",
    "#test_x, test_y = generate_triplets(x_test_master, y_test_master,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YriH-06myvL4"
   },
   "outputs": [],
   "source": [
    "def triplet_loss(inputs, dist='sqeuclidean', margin='maxplus'):\n",
    "    anchor, positive, negative = inputs\n",
    "    positive_distance = K.square(anchor - positive)\n",
    "    negative_distance = K.square(anchor - negative)\n",
    "    if dist == 'euclidean':\n",
    "        positive_distance = K.sqrt(K.sum(positive_distance, axis=-1, keepdims=True))\n",
    "        negative_distance = K.sqrt(K.sum(negative_distance, axis=-1, keepdims=True))\n",
    "    elif dist == 'sqeuclidean':\n",
    "        positive_distance = K.sum(positive_distance, axis=-1, keepdims=True)\n",
    "        negative_distance = K.sum(negative_distance, axis=-1, keepdims=True)\n",
    "    loss = positive_distance - negative_distance\n",
    "    if margin == 'maxplus':\n",
    "        loss = K.maximum(0.0, 1 + loss)\n",
    "    elif margin == 'softplus':\n",
    "        loss = K.log(1 + K.exp(loss))\n",
    "    return K.mean(loss)\n",
    "\n",
    "def get_embedding_model(input_shape, embedding_dim):\n",
    "    _input = Input(shape=input_shape)\n",
    "    x = Flatten()(_input)\n",
    "    x = Dense(embedding_dim * 8,activation=\"relu\")(x)\n",
    "    x = Dense(embedding_dim * 2, activation='relu')(x)\n",
    "    x = Dense(embedding_dim)(x)\n",
    "    return Model(_input, x)\n",
    "        \n",
    "\n",
    "def get_siamese_model(input_shape, triplet_margin=.3, embedding_dim=50):\n",
    "    \"\"\"\n",
    "        Model architecture\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the tensors for the triplet of input images\n",
    "    anchor_input = Input(input_shape, name=\"anchor_input\")\n",
    "    positive_input = Input(input_shape, name=\"positive_input\")\n",
    "    negative_input = Input(input_shape, name=\"negative_input\")\n",
    "    \n",
    "    # Convolutional Neural Network (same from earlier)\n",
    "    embedding_model = get_embedding_model(input_shape, embedding_dim)\n",
    "    \n",
    "    # Generate the embedding outputs \n",
    "    encoded_anchor = embedding_model(anchor_input)\n",
    "    encoded_positive = embedding_model(positive_input)\n",
    "    encoded_negative = embedding_model(negative_input)\n",
    "    \n",
    "    inputs = [anchor_input, positive_input, negative_input]\n",
    "    outputs = [encoded_anchor, encoded_positive, encoded_negative]\n",
    "    \n",
    "    # Connect the inputs with the outputs\n",
    "    siamese_triplet = Model(inputs=inputs,outputs=outputs)\n",
    "    \n",
    "    siamese_triplet.add_loss((triplet_loss(outputs, dist='euclidean', margin='maxplus')))\n",
    "    \n",
    "    # return the model\n",
    "    return embedding_model, siamese_triplet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K5L5fkP0TsG8"
   },
   "source": [
    "# Siamese NN trained on all classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k4XDxcxYS2m8"
   },
   "outputs": [],
   "source": [
    "def shuffle_triplets(inputs, labels):\n",
    "  a, p, n = inputs\n",
    "  l1, l2, l3 = labels\n",
    "  randomizer = np.random.choice(a.shape[0], a.shape[0], replace=False)\n",
    "  a = a[randomizer]\n",
    "  p = p[randomizer]\n",
    "  n = n[randomizer]\n",
    "\n",
    "  l1 = l1[randomizer]\n",
    "  l2 = l2[randomizer]\n",
    "  l3 = l3[randomizer]\n",
    "  return [a, p, n], [l1,l2,l3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "55eKWdSsU5sM"
   },
   "outputs": [],
   "source": [
    "train_x, train_y = shuffle_triplets(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 403
    },
    "colab_type": "code",
    "id": "xTNyt7BqTMGm",
    "outputId": "13b04928-1690-4360-c5c5-f916cdc977e4"
   },
   "outputs": [],
   "source": [
    "embedding_model2, siamese_triplet2 = get_siamese_model((60,60,1), triplet_margin=.3, embedding_dim=150)\n",
    "siamese_triplet2.compile(loss=None, optimizer=Adam(0.0001))\n",
    "history_s2 = siamese_triplet2.fit(x=train_x, shuffle=True, batch_size=1000,\n",
    "                              validation_split=.1, epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zxpXvHBqTm4l"
   },
   "outputs": [],
   "source": [
    "train_embeds = embedding_model2.predict(np.vstack((train_x[0], train_x[1], train_x[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XscrWCk0Tm45"
   },
   "outputs": [],
   "source": [
    "target = np.hstack((train_y[0], train_y[1], train_y[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1h3bzWKwTm5A"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "def fit_nearest_neighbor(img_encoding, img_class, algorithm='ball_tree'):\n",
    "    classifier = KNeighborsClassifier(n_neighbors=3, algorithm=algorithm)\n",
    "    classifier.fit(img_encoding, img_class)\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ge6_SAKpTm5F"
   },
   "outputs": [],
   "source": [
    "classifier2 = fit_nearest_neighbor(train_embeds, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EFLnVUYpTm5L"
   },
   "outputs": [],
   "source": [
    "e2 = embedding_model2.predict(x_train_master)\n",
    "op2 = classifier2.predict(e2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "MdaQqZsNTm5V",
    "outputId": "4b0c2e46-9b96-4b73-af37-5f0aa7a9b50b"
   },
   "outputs": [],
   "source": [
    "(np.where(y_train_master == op2))[0].shape[0] / y_train_master.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dxDOQjGKTm5b"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "mat = confusion_matrix(y_train_master, op2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ESIgCRMBTm5g",
    "outputId": "2733471e-0d4a-4d66-80a1-15eabc2def84"
   },
   "outputs": [],
   "source": [
    "# import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "RVek-Qok-qRb"
   },
   "outputs": [],
   "source": [
    "# sns.heatmap(mat, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save classsifier model\n",
    "# Its important to use binary mode \n",
    "knnPickle = open('knnpickle_file', 'wb')\n",
    "# source, destination \n",
    "pickle.dump(classifier2, knnPickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QBHqZ9YdPh80"
   },
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = embedding_model2.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "embedding_model2.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Siamese - Fashion Mnist.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
